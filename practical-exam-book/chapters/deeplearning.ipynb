{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lihkir/Data/refs/heads/main/Bitcoin%20Historical%20Data.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.set_index(\"Date\")\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeserie  = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series(data, tau, train_size=7, jump=0):\n",
    "    \"\"\"\n",
    "    train_size:\n",
    "    tau:\n",
    "    \"\"\"\n",
    "    n_samples = len(data)\n",
    "    \n",
    "    dim_train_size = 14\n",
    "    dim_tau_size = 7\n",
    "    total_dim = dim_train_size + dim_tau_size * 2\n",
    "\n",
    "    splits = []\n",
    "    id_counter = 1\n",
    "    dim = 1\n",
    "    split_counter = 0\n",
    "\n",
    "    for start in range(0, n_samples - train_size - tau*2 + jump, 1):\n",
    "        if split_counter == 0:\n",
    "            if start + total_dim > n_samples - train_size - tau * 2 + jump:\n",
    "                break  # No hay suficientes datos\n",
    "\n",
    "        x_train_end = start + train_size + jump\n",
    "        y_tain = x_train_end + tau\n",
    "\n",
    "        if split_counter < dim_train_size:\n",
    "            split_type  = \"train\"\n",
    "        elif split_counter < dim_train_size + dim_tau_size:\n",
    "            split_type  = \"val\"\n",
    "        elif split_counter < dim_train_size + dim_tau_size*2:\n",
    "            split_type  = \"test\"\n",
    "        else:\n",
    "            # Reset\n",
    "            dim += 1\n",
    "            split_counter = 0\n",
    "            split_type = \"train\"\n",
    "        \n",
    "        split_dict = {\n",
    "            \"id\": id_counter,\n",
    "            \"dim\": dim,\n",
    "            \"split\": split_type,\n",
    "            \"X\": [data.iloc[start:x_train_end]],  \n",
    "            \"y\": [data.iloc[x_train_end:y_tain]]\n",
    "        }\n",
    "\n",
    "        splits.append(split_dict)\n",
    "\n",
    "        # Incrementar los contadores\n",
    "        id_counter += 1\n",
    "        split_counter += 1\n",
    "\n",
    "        if split_counter >= total_dim:\n",
    "            dim += 1\n",
    "            split_counter = 0\n",
    "\n",
    "    return splits\n",
    "\n",
    "array = split_time_series(data=timeserie, tau=1)\n",
    "df_model = pd.DataFrame(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dim</th>\n",
       "      <th>split</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]</td>\n",
       "      <td>[[0.1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]</td>\n",
       "      <td>[[0.1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]</td>\n",
       "      <td>[[0.1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]</td>\n",
       "      <td>[[0.1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>[[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]</td>\n",
       "      <td>[[0.1]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  dim  split                                      X        y\n",
       "0   1    1  train  [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]  [[0.1]]\n",
       "1   2    1  train  [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]  [[0.1]]\n",
       "2   3    1  train  [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]  [[0.1]]\n",
       "3   4    1  train  [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]  [[0.1]]\n",
       "4   5    1  train  [[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]]  [[0.1]]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_splits(data, splits, horizon, dim=1):\n",
    "    \"\"\"\n",
    "    Visualiza los pliegues de entrenamiento, validación y prueba para una dimensión específica.\n",
    "\n",
    "    Parámetros:\n",
    "    - data: pandas DataFrame o Series, la serie temporal completa.\n",
    "    - splits: lista de diccionarios, cada diccionario contiene información de un split.\n",
    "    - horizon: int, horizonte de predicción τ.\n",
    "    - dim: int, la dimensión a visualizar.\n",
    "    \"\"\"\n",
    "    # Filtrar los splits para la dimensión especificada\n",
    "    dim_splits = [s for s in splits if s['dim'] == dim]\n",
    "\n",
    "    if not dim_splits:\n",
    "        print(f\"No hay splits para la dimensión {dim}.\")\n",
    "        return\n",
    "\n",
    "    # Inicializar listas para almacenar los rangos de cada tipo de split\n",
    "    train_ranges = []\n",
    "    val_ranges = []\n",
    "    test_ranges = []\n",
    "\n",
    "    for split in dim_splits:\n",
    "        split_type = split['split']\n",
    "        X = split['X'][0]\n",
    "        y = split['y'][0]\n",
    "        \n",
    "        # Obtener los índices de inicio y fin\n",
    "        start = X.index[0]\n",
    "        end = y.index[-1]\n",
    "        \n",
    "        if split_type == 'train':\n",
    "            train_ranges.append((start, end))\n",
    "        elif split_type == 'val':\n",
    "            val_ranges.append((start, end))\n",
    "        elif split_type == 'test':\n",
    "            test_ranges.append((start, end))\n",
    "\n",
    "    # Configurar el gráfico\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(data.index, data, label='Datos', color='black')\n",
    "\n",
    "    # Función auxiliar para evitar múltiples etiquetas en la leyenda\n",
    "    def add_axvspan(ranges, color, label):\n",
    "        for i, (start, end) in enumerate(ranges):\n",
    "            if i == 0:\n",
    "                plt.axvspan(start, end, color=color, alpha=0.4, label=label)\n",
    "            else:\n",
    "                plt.axvspan(start, end, color=color, alpha=0.4)\n",
    "\n",
    "    # Agregar áreas sombreadas para cada tipo de split\n",
    "    add_axvspan(train_ranges, 'green', 'Entrenamiento')\n",
    "    add_axvspan(val_ranges, 'blue', 'Validación')\n",
    "    add_axvspan(test_ranges, 'red', 'Prueba')\n",
    "\n",
    "    # Títulos y etiquetas\n",
    "    plt.title(f'Dimensión {dim} - Horizonte de Predicción: {horizon} días')\n",
    "    plt.xlabel('Índice de Tiempo')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mape, mae, rmse, mse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_model(model_type, neurons, dropout_rate, batch_size, X_train, y_train, X_val, y_val):\n",
    "    model = Sequential()\n",
    "    if model_type == 'MLP':\n",
    "        model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "    elif model_type == 'RNN':\n",
    "        model.add(SimpleRNN(neurons, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(neurons, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(1))\n",
    "    else:\n",
    "        raise ValueError(\"Tipo de modelo no soportado.\")\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=batch_size,\n",
    "                        validation_data=(X_val, y_val), verbose=0)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, jarque_bera\n",
    "\n",
    "# Hiperparámetros a explorar\n",
    "dropout_rates = [0.2, 0.4, 0.6, 0.8]\n",
    "neurons_list = [10, 100, 1000, 10000]\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_type in ['MLP', 'RNN', 'LSTM']:\n",
    "    for neurons in neurons_list:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for batch_size in batch_sizes:\n",
    "                # Preprocesamiento específico si es necesario\n",
    "                if model_type in ['RNN', 'LSTM']:\n",
    "                    X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "                    X_val_reshaped = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "                else:\n",
    "                    X_train_reshaped = X_train\n",
    "                    X_val_reshaped = X_val\n",
    "\n",
    "                model, history = create_and_train_model(model_type, neurons, dropout_rate, batch_size,\n",
    "                                                        X_train_reshaped, y_train, X_val_reshaped, y_val)\n",
    "                # Predicciones\n",
    "                y_pred_train = model.predict(X_train_reshaped)\n",
    "                y_pred_val = model.predict(X_val_reshaped)\n",
    "\n",
    "                # Cálculo de métricas para el conjunto de entrenamiento\n",
    "                mape_train, mae_train, rmse_train, mse_train, r2_train = calculate_metrics(y_train, y_pred_train)\n",
    "\n",
    "                # Pruebas estadísticas sobre los residuos del entrenamiento\n",
    "                residuals_train = y_train.flatten() - y_pred_train.flatten()\n",
    "                lb_test = acorr_ljungbox(residuals_train, lags=[10], return_df=True)\n",
    "                jb_test = jarque_bera(residuals_train)\n",
    "\n",
    "                # Guardar los resultados\n",
    "                results.append({\n",
    "                    'Model': model_type,\n",
    "                    'Neurons': neurons,\n",
    "                    'Dropout': dropout_rate,\n",
    "                    'BatchSize': batch_size,\n",
    "                    'MAPE': mape_train,\n",
    "                    'MAE': mae_train,\n",
    "                    'RMSE': rmse_train,\n",
    "                    'MSE': mse_train,\n",
    "                    'R2': r2_train,\n",
    "                    'Ljung-Box p-value': lb_test['lb_pvalue'].values[0],\n",
    "                    'Jarque-Bera p-value': jb_test[1],\n",
    "                    'History': history,\n",
    "                    'Residuals': residuals_train\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_train = results_df[['Model', 'Neurons', 'Dropout', 'BatchSize', 'MAPE', 'MAE', 'RMSE', 'MSE', 'R2',\n",
    "                          'Ljung-Box p-value', 'Jarque-Bera p-value']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repite el proceso de evaluación para el conjunto de prueba\n",
    "for result in results:\n",
    "    model = result['Model']\n",
    "    neurons = result['Neurons']\n",
    "    dropout_rate = result['Dropout']\n",
    "    batch_size = result['BatchSize']\n",
    "    trained_model = result['Model']\n",
    "\n",
    "    # Preprocesamiento específico si es necesario\n",
    "    if model in ['RNN', 'LSTM']:\n",
    "        X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    else:\n",
    "        X_test_reshaped = X_test\n",
    "\n",
    "    y_pred_test = trained_model.predict(X_test_reshaped)\n",
    "    mape_test, mae_test, rmse_test, mse_test, r2_test = calculate_metrics(y_test, y_pred_test)\n",
    "\n",
    "    # Prueba de independencia\n",
    "    residuals_test = y_test.flatten() - y_pred_test.flatten()\n",
    "    lb_test = acorr_ljungbox(residuals_test, lags=[10], return_df=True)\n",
    "\n",
    "    result['MAPE_test'] = mape_test\n",
    "    result['MAE_test'] = mae_test\n",
    "    result['RMSE_test'] = rmse_test\n",
    "    result['MSE_test'] = mse_test\n",
    "    result['R2_test'] = r2_test\n",
    "    result['Ljung-Box p-value_test'] = lb_test['lb_pvalue'].values[0]\n",
    "\n",
    "table_test = results_df[['Model', 'Neurons', 'Dropout', 'BatchSize', 'MAPE_test', 'MAE_test', 'RMSE_test', 'MSE_test', 'R2_test', 'Ljung-Box p-value_test']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for result in results:\n",
    "    history = result['History']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f\"Modelo: {result['Model']}, Neuronas: {result['Neurons']}, Dropout: {result['Dropout']}\")\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = [result['MAE'] for result in results]\n",
    "val_errors = [result['MAE_test'] for result in results]  # Usamos MAE_test para validación si está disponible\n",
    "test_errors = [result['MAE_test'] for result in results]\n",
    "\n",
    "data = [train_errors, val_errors, test_errors]\n",
    "labels = ['Entrenamiento', 'Validación', 'Prueba']\n",
    "\n",
    "plt.boxplot(data, labels=labels)\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Distribución de Errores MAE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = min(results, key=lambda x: x['RMSE'])\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "model = best_result['Model']\n",
    "trained_model = best_result['Model']\n",
    "\n",
    "if model in ['RNN', 'LSTM']:\n",
    "    X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "else:\n",
    "    X_test_reshaped = X_test\n",
    "\n",
    "y_pred_test = trained_model.predict(X_test_reshaped)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(y_test)), y_test, label='Real')\n",
    "plt.plot(range(len(y_pred_test)), y_pred_test, label='Predicción')\n",
    "plt.title('Predicción vs Real en el Conjunto de Prueba')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[163], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Serie de residuos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mbest_result\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResiduals\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSerie de Residuos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_result' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Serie de residuos\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(best_result['Residuals'])\n",
    "plt.title('Serie de Residuos')\n",
    "plt.show()\n",
    "\n",
    "# QQPlot\n",
    "sm.qqplot(best_result['Residuals'], line='s')\n",
    "plt.title('QQ Plot de Residuos')\n",
    "plt.show()\n",
    "\n",
    "# ACF de residuos\n",
    "plot_acf(best_result['Residuals'], lags=20)\n",
    "plt.title('ACF de Residuos')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
